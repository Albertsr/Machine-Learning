{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共线性对模型有如下4种效应"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数的估计值变得不准确\n",
    "- 参数估计值的标准差变大\n",
    "- 参数显著性检验变得不准确，容易将重要的自变量误判为不显著，即针对模型参数的假设检验变得不准确\n",
    "- 对于已知数据，模型的预测效果几乎不受影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "dataset = datasets.make_classification(n_samples=5000, n_features=15, n_informative=5, n_redundant=2, n_repeated=2, \n",
    "                                       n_classes=2, n_clusters_per_class=2, shuffle=True, random_state=2018)\n",
    "X, y = dataset[0], dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5593271141268006, 0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats.stats as scss\n",
    "\n",
    "# 第一个值是相关系数，第二个值是P值\n",
    "scss.pearsonr(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.48175831850233264, pvalue=5.732959707734371e-289)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scss.spearmanr(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 岭回归(L2正则项)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在线性回归模型中加入L2惩罚项能比较有效地解决共线性问题\n",
    "- 岭回归是一种可用于共线性问题的有偏估计回归方法，实质上是一种改良的最小二乘估计法\n",
    "- 它通过放弃最小二乘法的无偏性，以损失部分信息、降低精读为代价来获得更实际和可靠性更强的回归系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef:\n",
      " [-0.00836161 -0.10320428 -0.01964247 -0.00560743  0.02988531 -0.00410644\n",
      "  0.00484214 -0.03720753  0.02489295  0.02489295  0.00527641  0.06280543\n",
      " -0.00212993 -0.03720753 -0.00726083]\n",
      "\n",
      "intercept:\n",
      " 0.6222527142570053\n"
     ]
    }
   ],
   "source": [
    "model_ridge = Ridge(alpha=1.0)\n",
    "model_ridge.fit(X, y)\n",
    "print('coef:\\n', model_ridge.coef_)\n",
    "print('\\nintercept:\\n', model_ridge.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过主成分分析，将原始特征转换为少数几个主成分，每个主成分是原特征的线性组合\n",
    "- 基于主成分做回归分析，可以在不丢失重要数据特征的前提下避开共线性问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio_cumsum:\n",
      " [0.29512698 0.48842363 0.62481032 0.74903408 0.79338958 0.82974707\n",
      " 0.865346   0.90040382 0.93489478 0.96783082 1.         1.\n",
      " 1.         1.         1.        ]\n",
      "\n",
      "rule_index: \n",
      " (array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int64),)\n",
      "\n",
      "shape:\n",
      " (5000, 6)\n"
     ]
    }
   ],
   "source": [
    "model_pca = PCA()\n",
    "data_pca = model_pca.fit_transform(X)\n",
    "\n",
    "# np.cumsum(a, axis=None, dtype=None, out=None)可以在指定的axis上累计求和\n",
    "ratio_cumsum = np.cumsum(model_pca.explained_variance_ratio_)\n",
    "print('ratio_cumsum:\\n', ratio_cumsum)\n",
    "\n",
    "# 获取主成分方差占比累积大于0.8的值索引\n",
    "rule_index = np.where(ratio_cumsum > 0.8)\n",
    "print('\\nrule_index: \\n', rule_index)\n",
    "\n",
    "# rule_index是一个元组，min_index为其最小值\n",
    "min_index = rule_index[0][0]\n",
    "\n",
    "# 获取data_pca的所有行，前min_index列.\n",
    "data_pca_result = data_pca[:, :(min_index + 1)]\n",
    "print('\\nshape:\\n', data_pca_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef: [ 0.03679445  0.04293586 -0.08639767 -0.01217279 -0.09520728  0.00861532]\n",
      "\n",
      "intercept 0.4988\n"
     ]
    }
   ],
   "source": [
    "model_linear = LinearRegression()\n",
    "model_linear.fit(data_pca_result, y)\n",
    "\n",
    "print('coef:', model_linear.coef_)\n",
    "print('\\nintercept', model_linear.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
